<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Serif+SC:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css" integrity="sha256-CTSx/A06dm1B063156EVh15m6Y67pAjZZaQc89LLSrU=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Mist","darkmode":false,"version":"8.18.2","exturl":false,"sidebar":{"position":"right","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="Segment-Anything（分割一切）模型，又称SAM，是2023年提出的视觉分割领域的通用大模型，可以通过各种prompt（点击、bbox、mask等）提供的信息，引导模型直接输出想要的分割结果，另外也可以直接对图像进行整图分割解析。">
<meta property="og:type" content="article">
<meta property="og:title" content="Segment-Anything模型（SAM）基本原理与代码分析">
<meta property="og:url" content="http://example.com/2024/01/06/SAM/index.html">
<meta property="og:site_name" content="Brain in Machine">
<meta property="og:description" content="Segment-Anything（分割一切）模型，又称SAM，是2023年提出的视觉分割领域的通用大模型，可以通过各种prompt（点击、bbox、mask等）提供的信息，引导模型直接输出想要的分割结果，另外也可以直接对图像进行整图分割解析。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/2024/01/06/SAM/image-20240301092757321.png">
<meta property="og:image" content="http://example.com/2024/01/06/SAM/image-20240301093810681.png">
<meta property="og:image" content="http://example.com/2024/01/06/SAM/sam_decoder.png">
<meta property="article:published_time" content="2024-01-06T15:46:19.000Z">
<meta property="article:modified_time" content="2024-04-24T15:31:57.970Z">
<meta property="article:author" content="jzsherlock">
<meta property="article:tag" content="segmentation">
<meta property="article:tag" content="large model">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2024/01/06/SAM/image-20240301092757321.png">


<link rel="canonical" href="http://example.com/2024/01/06/SAM/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"http://example.com/2024/01/06/SAM/","path":"2024/01/06/SAM/","title":"Segment-Anything模型（SAM）基本原理与代码分析"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Segment-Anything模型（SAM）基本原理与代码分析 | Brain in Machine</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Brain in Machine</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">机中之脑？缸中之脑？</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#segment-anything%E7%AE%80%E4%BB%8B"><span class="nav-number">1.</span> <span class="nav-text">Segment Anything简介</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#sam%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%95%B4%E4%BD%93%E7%BB%93%E6%9E%84%E4%B8%8E%E5%9F%BA%E6%9C%AC%E9%A3%8E%E6%A0%BC"><span class="nav-number">2.</span> <span class="nav-text">SAM模型的整体结构与基本风格</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90"><span class="nav-number">3.</span> <span class="nav-text">代码分析</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#encoder%E7%BB%86%E8%8A%82"><span class="nav-number">3.1.</span> <span class="nav-text">Encoder细节</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#imageencodervit"><span class="nav-number">3.1.1.</span> <span class="nav-text">ImageEncoderViT</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#promptencoder"><span class="nav-number">3.1.2.</span> <span class="nav-text">PromptEncoder</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#decoder%E7%BB%86%E8%8A%82"><span class="nav-number">3.2.</span> <span class="nav-text">Decoder细节</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#reference"><span class="nav-number">4.</span> <span class="nav-text">Reference</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="jzsherlock"
      src="/images/lawliet.jpeg">
  <p class="site-author-name" itemprop="name">jzsherlock</p>
  <div class="site-description" itemprop="description">Wir mussen wissen. Wir werden wissen.</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">17</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">13</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">27</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/jzsherlock4869" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;jzsherlock4869" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:jzsherlock@163.com" title="E-Mail → mailto:jzsherlock@163.com" rel="noopener me" target="_blank"><i class="fas fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/01/06/SAM/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/lawliet.jpeg">
      <meta itemprop="name" content="jzsherlock">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Brain in Machine">
      <meta itemprop="description" content="Wir mussen wissen. Wir werden wissen.">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="Segment-Anything模型（SAM）基本原理与代码分析 | Brain in Machine">
      <meta itemprop="description" content="Segment-Anything（分割一切）模型，又称SAM，是2023年提出的视觉分割领域的通用大模型，可以通过各种prompt（点击、bbox、mask等）提供的信息，引导模型直接输出想要的分割结果，另外也可以直接对图像进行整图分割解析。">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Segment-Anything模型（SAM）基本原理与代码分析
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-01-06 23:46:19" itemprop="dateCreated datePublished" datetime="2024-01-06T23:46:19+08:00">2024-01-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-04-24 23:31:57" itemprop="dateModified" datetime="2024-04-24T23:31:57+08:00">2024-04-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Computer-Vision/" itemprop="url" rel="index"><span itemprop="name">Computer Vision</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Computer-Vision/Segmentation/" itemprop="url" rel="index"><span itemprop="name">Segmentation</span></a>
        </span>
    </span>

  
</div>

            <div class="post-description">Segment-Anything（分割一切）模型，又称SAM，是2023年提出的视觉分割领域的通用大模型，可以通过各种prompt（点击、bbox、mask等）提供的信息，引导模型直接输出想要的分割结果，另外也可以直接对图像进行整图分割解析。</div>
        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h1 id="segment-anything简介">Segment Anything简介</h1>
<p>SAM即Segment Anything，其目的在于构建一个分割领域的foundation model，用于zero-shot任务，以及交互式prompt分割任务。其结构如下所示。SAM具有大模型的encoder提图像特征，然后通过轻量的prompt encoder和mask decoder将提示转为embedding，并与图像的特征embedding进行交互（仍然是基于transformer），最后输出mask。</p>
<figure>
<img src="image-20240301092757321.png" alt="SAM模型整体结构"><figcaption aria-hidden="true">SAM模型整体结构</figcaption>
</figure>
<p>SAM作为foundation model，其输出的mask并非为某类或者某些特定类别的物体，而是一个广义的“object”或者“stuff”的概念，因此会有一定的歧义性（比如，将一个人的上半身的一个点作prompt，我们无法判断想要分割的是这个人的衣服，还是整个人等等），因此SAM可以支持multimask输出，并根据需要选择合适的mask。</p>
<h1 id="sam模型的整体结构与基本风格">SAM模型的整体结构与基本风格</h1>
<p>设计原则：</p>
<ul>
<li><p>遵循scaling law的思路，希望通过大模型、大数据量（data-driven），使得模型学习到（涌现出）类别/任务无关的“object”概念，成为视觉领域的通用模型，而不是针对某类任务或者某种特定类别训练模型</p></li>
<li><p>可prompt，可以交互输入一定先验信息，利用SAM的语义能力，完成开集分割（SAM无需知道分割的对象的各种类别信息，关于对象的信息被编码到prompt中）</p></li>
<li><p>prompt的多模态性：支持多种prompt类型，比如point、box、dense mask以及text（需要图文多模module如CLIP支持，将text的隐空间关联到图像的隐空间）</p></li>
<li><p>zero-shot能力/OpenSet能力：不指定任务，可以直接迁移到众多下游子任务中（当然后续研究发现对于特殊场景，比如医学图像、隐藏目标分割等，还是无法较好处理，但是语义能力仍可用，因此出现了SAMed、Adapter-SAM等方案将其迁移到特殊任务中）</p></li>
</ul>
<p>整体训练过程：</p>
<p>SAM的训练和标注流程比较特殊，它并非通常的先标注-再训练-最后得到结果的这种范式，而是将标注（annotation）和模型训练（training）闭环，形成一个data engine的策略，即一边用标注数据训网络，一边用网络产生标注，从而可以整体运转，获得更多的标注数据训练模型，提高模型的效果。SAM论文中将训练过程主要分为三个阶段：</p>
<ul>
<li><p>手工协助阶段（assisted-manual stage）</p></li>
<li><p>半自动阶段（semi-automatic stage）</p></li>
<li><p>全自动阶段（full-automatic stage）</p></li>
</ul>
<figure>
<img src="image-20240301093810681.png" alt="SAM的任务、结构与训练过程"><figcaption aria-hidden="true">SAM的任务、结构与训练过程</figcaption>
</figure>
<h1 id="代码分析">代码分析</h1>
<h2 id="encoder细节">Encoder细节</h2>
<p>分为image encoder和prompt encoder，重点关注prompt encoder。</p>
<h3 id="imageencodervit">ImageEncoderViT</h3>
<p>采用ViT架构，对图像做encode，图像固定尺寸输入<code>(1024, 1024)</code> ，最后得到的隐编码尺寸为<code>(64, 64)</code> （patch size 为 16）。在SAM的训练阶段，采用了MAE预训练好的ViT做监督训练。在预测阶段，首先将读入的图像的长边resize到指定尺寸（比如1024），同时保持其aspect ratio。然后，沿着短边方向进行填充，得到正方形图像输入。</p>
<h3 id="promptencoder">PromptEncoder</h3>
<ul>
<li>sparse prompt</li>
</ul>
<p>为了适应不同的prompt类型，采用了多种不同的encoder。需要注意的是，即使point和bbox的prompt对于SAM也是进行编码送入网络处理的，因此不一定完全将point分割为指定类别，也不一定bbox prompt后的结果完全在bbox中，在SAM中这两者都只有提示大致位置的功能。</p>
<p>首先，PrompEncoder中设置了四种不同的embedding层：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">self.num_point_embeddings: <span class="built_in">int</span> = <span class="number">4</span>  <span class="comment"># pos/neg point + 2 box corners</span></span><br><span class="line">point_embeddings = [nn.Embedding(<span class="number">1</span>, embed_dim) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.num_point_embeddings)]</span><br><span class="line">self.point_embeddings = nn.ModuleList(point_embeddings)</span><br><span class="line">self.not_a_point_embed = nn.Embedding(<span class="number">1</span>, embed_dim)</span><br></pre></td></tr></table></figure>
<p>其中，<code>point_embeddings</code> 共有4个，分别表示四种不同的点，即：正样本、负样本、bbox的左上角点、bbox的右下角点。<code>nn.Embedding(1, embed_dim)</code>中的输入为vocab长度为1，即只有一个<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="6.331ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 2798.4 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path></g><g data-mml-node="mn" transform="translate(278,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(1000.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mi" transform="translate(2000.4,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mo" transform="translate(2520.4,0)"><path data-c="5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path></g></g></g></svg></mjx-container></span>的向量，其中d为embed_dim。这个向量是nn.Embedding的weight，因此随着训练更新。另外，对于没有point prompt的情况，也给一个embedding向量，即<code>not_a_point_embed</code>，这个embedding对应label既不是前景fg也不是背景bg时的占位向量。上述的embedding训练好后，可以用来指示点的类别。</p>
<p>另一方面，点的位置信息则通过 <strong>位置编码（Position Encoding，PE）</strong> 来实现。PE的目的是将连续的位置信息映射到高频，从而增加不同位置的区分度。这里采用了<code>PositionEmbeddingRandom</code>实现。对正负样本point prompt和bbox的角点prompt进行PE编码后，与上面的点的类型编码结合（相加），得到最终的prompt encoding结果。</p>
<ol type="1">
<li>对point prompt（正负样本点）的编码：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_embed_points</span>(<span class="params"></span></span><br><span class="line"><span class="params">    self,</span></span><br><span class="line"><span class="params">    points: torch.Tensor,</span></span><br><span class="line"><span class="params">    labels: torch.Tensor,</span></span><br><span class="line"><span class="params">    pad: <span class="built_in">bool</span>,</span></span><br><span class="line"><span class="params"></span>) -&gt; torch.Tensor:</span><br><span class="line">    <span class="string">"""Embeds point prompts."""</span></span><br><span class="line">    points = points + <span class="number">0.5</span>  <span class="comment"># Shift to center of pixel</span></span><br><span class="line">    <span class="keyword">if</span> pad:</span><br><span class="line">        padding_point = torch.zeros((points.shape[<span class="number">0</span>], <span class="number">1</span>, <span class="number">2</span>), device=points.device)</span><br><span class="line">        padding_label = -torch.ones((labels.shape[<span class="number">0</span>], <span class="number">1</span>), device=labels.device)</span><br><span class="line">        points = torch.cat([points, padding_point], dim=<span class="number">1</span>)</span><br><span class="line">        labels = torch.cat([labels, padding_label], dim=<span class="number">1</span>)</span><br><span class="line">    point_embedding = self.pe_layer.forward_with_coords(points, self.input_image_size)</span><br><span class="line">    point_embedding[labels == -<span class="number">1</span>] = <span class="number">0.0</span></span><br><span class="line">    point_embedding[labels == -<span class="number">1</span>] += self.not_a_point_embed.weight</span><br><span class="line">    point_embedding[labels == <span class="number">0</span>] += self.point_embeddings[<span class="number">0</span>].weight</span><br><span class="line">    point_embedding[labels == <span class="number">1</span>] += self.point_embeddings[<span class="number">1</span>].weight</span><br><span class="line">    <span class="keyword">return</span> point_embedding</span><br></pre></td></tr></table></figure>
<ol start="2" type="1">
<li>对bbox prompt的编码（top-left和bottom-right两角点）</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_embed_boxes</span>(<span class="params">self, boxes: torch.Tensor</span>) -&gt; torch.Tensor:</span><br><span class="line">    <span class="string">"""Embeds box prompts."""</span></span><br><span class="line">    boxes = boxes + <span class="number">0.5</span>  <span class="comment"># Shift to center of pixel</span></span><br><span class="line">    coords = boxes.reshape(-<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">    corner_embedding = self.pe_layer.forward_with_coords(coords, self.input_image_size)</span><br><span class="line">    corner_embedding[:, <span class="number">0</span>, :] += self.point_embeddings[<span class="number">2</span>].weight</span><br><span class="line">    corner_embedding[:, <span class="number">1</span>, :] += self.point_embeddings[<span class="number">3</span>].weight</span><br><span class="line">    <span class="keyword">return</span> corner_embedding</span><br></pre></td></tr></table></figure>
<ul>
<li>dense prompt</li>
</ul>
<p>SAM中的dense prompt即mask输入。对于mask的处理，SAM通过一个下采样卷积层将其resize到与image embedding同等大小，然后相加。（由于<code>mask_downscaling</code>下采样了4倍，因此<code>mask_input_size</code> 需要被设置为<code>image_embedding_size</code>的4倍）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">self.mask_input_size = (<span class="number">4</span> * image_embedding_size[<span class="number">0</span>], <span class="number">4</span> * image_embedding_size[<span class="number">1</span>])</span><br><span class="line">self.mask_downscaling = nn.Sequential(</span><br><span class="line">    nn.Conv2d(<span class="number">1</span>, mask_in_chans // <span class="number">4</span>, kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>),</span><br><span class="line">    LayerNorm2d(mask_in_chans // <span class="number">4</span>),</span><br><span class="line">    activation(),</span><br><span class="line">    nn.Conv2d(mask_in_chans // <span class="number">4</span>, mask_in_chans, kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>),</span><br><span class="line">    LayerNorm2d(mask_in_chans),</span><br><span class="line">    activation(),</span><br><span class="line">    nn.Conv2d(mask_in_chans, embed_dim, kernel_size=<span class="number">1</span>),</span><br><span class="line">)</span><br><span class="line">self.no_mask_embed = nn.Embedding(<span class="number">1</span>, embed_dim)</span><br></pre></td></tr></table></figure>
<p>同时，对于没有dense mask的情况，也训练一个embedding作为占位符，该向量在spatial（即H和W）方向上进行复制，得到和dense mask embedding相同的张量，与image embedding相加。</p>
<ul>
<li>各种prompt的合并组装</li>
</ul>
<p>在forward中，对各个prompt进行组装，基本原则是sparse prompt（即各种点）得到的embedding向量沿着dim=1进行cat，即得到<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="10.603ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 4686.3 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path></g><g data-mml-node="mi" transform="translate(278,0)"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mi" transform="translate(707,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mo" transform="translate(1176,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(1620.7,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(2220.7,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(2665.3,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mi" transform="translate(3185.3,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(3530.3,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(4408.3,0)"><path data-c="5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path></g></g></g></svg></mjx-container></span> 的结果。其中<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.357ex" height="1.025ex" role="img" focusable="false" viewBox="0 -442 600 453"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g></g></g></svg></mjx-container></span>表示点的数量。而dense mask编码成dense embedding，无dense mask时直接复制<code>no_mask_embed</code>中的权重向量。注意，这里的各种prompt都是可选的（optional）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params"></span></span><br><span class="line"><span class="params">    self,</span></span><br><span class="line"><span class="params">    points: <span class="type">Optional</span>[<span class="type">Tuple</span>[torch.Tensor, torch.Tensor]],</span></span><br><span class="line"><span class="params">    boxes: <span class="type">Optional</span>[torch.Tensor],</span></span><br><span class="line"><span class="params">    masks: <span class="type">Optional</span>[torch.Tensor],</span></span><br><span class="line"><span class="params"></span>) -&gt; <span class="type">Tuple</span>[torch.Tensor, torch.Tensor]:</span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Embeds different types of prompts, returning both sparse and dense</span></span><br><span class="line"><span class="string">    embeddings.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">        points (tuple(torch.Tensor, torch.Tensor) or none): point coordinates</span></span><br><span class="line"><span class="string">        and labels to embed.</span></span><br><span class="line"><span class="string">        boxes (torch.Tensor or none): boxes to embed</span></span><br><span class="line"><span class="string">        masks (torch.Tensor or none): masks to embed</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        torch.Tensor: sparse embeddings for the points and boxes, with shape</span></span><br><span class="line"><span class="string">        BxNx(embed_dim), where N is determined by the number of input points</span></span><br><span class="line"><span class="string">        and boxes.</span></span><br><span class="line"><span class="string">        torch.Tensor: dense embeddings for the masks, in the shape</span></span><br><span class="line"><span class="string">        Bx(embed_dim)x(embed_H)x(embed_W)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    bs = self._get_batch_size(points, boxes, masks)</span><br><span class="line">    sparse_embeddings = torch.empty((bs, <span class="number">0</span>, self.embed_dim), device=self._get_device())</span><br><span class="line">    <span class="keyword">if</span> points <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        coords, labels = points</span><br><span class="line">        point_embeddings = self._embed_points(coords, labels, pad=(boxes <span class="keyword">is</span> <span class="literal">None</span>))</span><br><span class="line">        sparse_embeddings = torch.cat([sparse_embeddings, point_embeddings], dim=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">if</span> boxes <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        box_embeddings = self._embed_boxes(boxes)</span><br><span class="line">        sparse_embeddings = torch.cat([sparse_embeddings, box_embeddings], dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> masks <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        dense_embeddings = self._embed_masks(masks)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        dense_embeddings = self.no_mask_embed.weight.reshape(<span class="number">1</span>, -<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>).expand(</span><br><span class="line">            bs, -<span class="number">1</span>, self.image_embedding_size[<span class="number">0</span>], self.image_embedding_size[<span class="number">1</span>]</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> sparse_embeddings, dense_embeddings</span><br></pre></td></tr></table></figure>
<h2 id="decoder细节">Decoder细节</h2>
<p>SAM中的<code>MaskDecoder</code> 是一个轻量化的结构，便于交互式分割响应。其基本结构如图所示：</p>
<figure>
<img src="sam_decoder.png" alt="MaskDecoder结构示意图"><figcaption aria-hidden="true">MaskDecoder结构示意图</figcaption>
</figure>
<p>首先，如前所述，图像被编码成为<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="7.291ex" height="1.581ex" role="img" focusable="false" viewBox="0 -677 3222.4 699"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z"></path><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z" transform="translate(500,0)"></path></g><g data-mml-node="mo" transform="translate(1222.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(2222.4,0)"><path data-c="36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z"></path><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z" transform="translate(500,0)"></path></g></g></g></svg></mjx-container></span>大小的feature，每个feature维度为256。上面的各种prompt最终也被编码成为同样长度（256）的特征向量，作为token与图像进行attention的交互。</p>
<p>具体实现如下：</p>
<ol type="1">
<li>先考虑需要输出的mask和iou的形式，这里：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">self.num_mask_tokens = num_multimask_outputs + <span class="number">1</span></span><br></pre></td></tr></table></figure>
<p><code>num_multimask_outputs</code> 这里设定为3。由于SAM支持两种模式：multimask和直接输出单一mask，因此需要+1。除了mask的token之外，还需要预测每个mask的iou，因此还需要一个iou token，经过Transformer处理后的iou token接入一个MLP网络，网络输出维度等于mask个数，因此为每个mask分配了一个iou分数。mask token处理后与一个经过Transformer + upscaling（2x transposed conv实现）的处理后的image embedding进行逐像素点乘，最终得到对应的mask。</p>
<ol start="2" type="1">
<li>下面来看<code>MaskDecoder</code>输入的形式，以及如何将prompt融合进来的。首先，mask token 和 iou token 也被设置为<code>nn.Embedding</code>层的权重，即：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">self.iou_token = nn.Embedding(<span class="number">1</span>, transformer_dim)</span><br><span class="line">self.num_mask_tokens = num_multimask_outputs + <span class="number">1</span></span><br><span class="line">self.mask_tokens = nn.Embedding(self.num_mask_tokens, transformer_dim)</span><br></pre></td></tr></table></figure>
<p>由于我们还有 <code>PromptEncoder</code> 编码来的稀疏和稠密prompt embeding，其中代表mask的稠密embedding比较简单，直接将其与图像embedding相加即可；对于稀疏prompt，将它们与前面的mask token和iou token在通道维度上拼接，得到输入Transformer的tokens：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">output_tokens = torch.cat([self.iou_token.weight, self.mask_tokens.weight], dim=<span class="number">0</span>)</span><br><span class="line">output_tokens = output_tokens.unsqueeze(<span class="number">0</span>).expand(sparse_prompt_embeddings.size(<span class="number">0</span>), -<span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line">tokens = torch.cat((output_tokens, sparse_prompt_embeddings), dim=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>接下来，<code>tokens</code>将与<code>image_embeddings</code>（包括dense mask embedding 和 image pe）一起输入到一个<code>TwoWayTransformer</code>，即图中的主体部分。该模块可以对tokens→image embedding和image embeddings → tokens两个方向进行cross attention操作，从而使得image embedding也接受tokens的修正。这个过程如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params"></span></span><br><span class="line"><span class="params">self, queries: Tensor, keys: Tensor, query_pe: Tensor, key_pe: Tensor</span></span><br><span class="line"><span class="params"></span>) -&gt; <span class="type">Tuple</span>[Tensor, Tensor]:</span><br><span class="line"><span class="comment"># Self attention block</span></span><br><span class="line"><span class="keyword">if</span> self.skip_first_layer_pe:</span><br><span class="line">    queries = self.self_attn(q=queries, k=queries, v=queries)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    q = queries + query_pe</span><br><span class="line">    attn_out = self.self_attn(q=q, k=q, v=queries)</span><br><span class="line">    queries = queries + attn_out</span><br><span class="line">queries = self.norm1(queries)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Cross attention block, tokens attending to image embedding</span></span><br><span class="line">q = queries + query_pe</span><br><span class="line">k = keys + key_pe</span><br><span class="line">attn_out = self.cross_attn_token_to_image(q=q, k=k, v=keys)</span><br><span class="line">queries = queries + attn_out</span><br><span class="line">queries = self.norm2(queries)</span><br><span class="line"></span><br><span class="line"><span class="comment"># MLP block</span></span><br><span class="line">mlp_out = self.mlp(queries)</span><br><span class="line">queries = queries + mlp_out</span><br><span class="line">queries = self.norm3(queries)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Cross attention block, image embedding attending to tokens</span></span><br><span class="line">q = queries + query_pe</span><br><span class="line">k = keys + key_pe</span><br><span class="line">attn_out = self.cross_attn_image_to_token(q=k, k=q, v=queries)</span><br><span class="line">keys = keys + attn_out</span><br><span class="line">keys = self.norm4(keys)</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> queries, keys</span><br></pre></td></tr></table></figure>
<p>可以看出，两次cross attention中，q和k互换，并且k和v来源相同。最开始是一个self-attention，第一个cross attention后还有一个MLP对attention后的token进行更新。</p>
<ol start="3" type="1">
<li>最后，mask的输出方式如下：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Upscale mask embeddings and predict masks using the mask tokens</span></span><br><span class="line">src = src.transpose(<span class="number">1</span>, <span class="number">2</span>).view(b, c, h, w)</span><br><span class="line">upscaled_embedding = self.output_upscaling(src)</span><br><span class="line">hyper_in_list: <span class="type">List</span>[torch.Tensor] = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.num_mask_tokens):</span><br><span class="line">    hyper_in_list.append(self.output_hypernetworks_mlps[i](mask_tokens_out[:, i, :]))</span><br><span class="line">hyper_in = torch.stack(hyper_in_list, dim=<span class="number">1</span>)</span><br><span class="line">b, c, h, w = upscaled_embedding.shape</span><br><span class="line">masks = (hyper_in @ upscaled_embedding.view(b, c, h * w)).view(b, -<span class="number">1</span>, h, w)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Generate mask quality predictions</span></span><br><span class="line">iou_pred = self.iou_prediction_head(iou_token_out)</span><br></pre></td></tr></table></figure>
<p>然后，可以根据是否设置输出 multimask，选择合适的输出mask：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Select the correct mask or masks for output</span></span><br><span class="line"><span class="keyword">if</span> multimask_output:</span><br><span class="line">    mask_slice = <span class="built_in">slice</span>(<span class="number">1</span>, <span class="literal">None</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    mask_slice = <span class="built_in">slice</span>(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">masks = masks[:, mask_slice, :, :]</span><br><span class="line">iou_pred = iou_pred[:, mask_slice]</span><br></pre></td></tr></table></figure>
<h1 id="reference">Reference</h1>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2304.02643">Segment Anything</a></p>
<p>https://github.com/facebookresearch/segment-anything</p>
<p>https://segment-anything.com/</p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/segmentation/" rel="tag"><i class="fa fa-tag"></i> segmentation</a>
              <a href="/tags/large-model/" rel="tag"><i class="fa fa-tag"></i> large model</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2024/01/06/Hough/" rel="prev" title="霍夫变换（Hough Transform）与广义霍夫变换（GHT）">
                  <i class="fa fa-angle-left"></i> 霍夫变换（Hough Transform）与广义霍夫变换（GHT）
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2024/01/06/3DGS/" rel="next" title="3D Gaussian Splatting原理简介">
                  3D Gaussian Splatting原理简介 <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">jzsherlock</span>
  </div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/mist/" rel="noopener" target="_blank">NexT.Mist</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/jzsherlock4869" class="github-corner" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>







  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"all","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
